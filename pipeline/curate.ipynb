{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "dev"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curate the final dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from dart_math.data import RespSampleVLLM\n",
    "from dart_math.eval import EvaluatorMathBatch\n",
    "from dart_math.utils import PROJ_HOME, init_logging, load_jsonl, save_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "    description=\"Grade: extract answers & judge correctness\", allow_abbrev=False\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--sample_dir\",\n",
    "    type=str,\n",
    "    nargs=\"+\",\n",
    "    default=[os.path.join(PROJ_HOME, \"data/res\")],\n",
    "    help=\"Path to save results of generation (and evaluation).\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--fname_pattern\",\n",
    "    type=str,\n",
    "    default=\".*\",\n",
    "    help=\"Regex pattern to filter file names in `sample_dir`.\",\n",
    ")\n",
    "parser.add_argument(\"--k_u\", type=int, default=50, help=\"$k_u$ for DARS-Unifrom.\")\n",
    "parser.add_argument(\n",
    "    \"--out_dset_path\",\n",
    "    type=str,\n",
    "    default=os.path.join(PROJ_HOME, \"data/dset.jsonl\"),\n",
    "    help=\"Path to save the dataset.\",\n",
    ")\n",
    "\n",
    "\n",
    "args, unk_args = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "dev"
    ]
   },
   "outputs": [],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples = []\n",
    "\n",
    "for sample_dir in args.sample_dir:\n",
    "    for samples_fname in os.listdir(sample_dir):\n",
    "        if not re.match(args.fname_pattern, samples_fname):\n",
    "            continue\n",
    "        samples_fpath = os.path.join(sample_dir, samples_fname)\n",
    "        samples = load_jsonl(samples_fpath)\n",
    "        all_samples.extend(samples)\n",
    "        logging.info(f\"Loaded {len(samples)} samples from {samples_fpath=}\")\n",
    "\n",
    "\n",
    "logging.info(\n",
    "    f\"Loaded {len(all_samples)} samples in total from {args.sample_dir=} with {args.fname_pattern=}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_correct_samples = [sample for sample in all_samples if sample[\"correct\"]]\n",
    "logging.info(f\"Found {len(all_correct_samples)} correct samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_df = pd.DataFrame(all_correct_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "dev"
    ]
   },
   "outputs": [],
   "source": [
    "correct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the distribution of dataset\n",
    "correct_df[\"dataset\"].value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_grouped_correct_df = correct_df.groupby(\"query\")\n",
    "# Get the number of correct samples for each query\n",
    "query_correct_count = query_grouped_correct_df.size()\n",
    "query_correct_count.describe(percentiles=[0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of correct samples for each query with histogram\n",
    "query_correct_count.plot(kind=\"hist\", bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick k_u correct samples for each query\n",
    "chosen_correct_df = query_grouped_correct_df.head(args.k_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "dev"
    ]
   },
   "outputs": [],
   "source": [
    "chosen_correct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_correct_df.to_json(args.out_dset_path, orient=\"records\", lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
