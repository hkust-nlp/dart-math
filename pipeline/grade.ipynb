{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "dev"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grade: extract answers & judge correctness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from dart_math.data import RespSampleVLLM\n",
    "from dart_math.eval import EvaluatorMathBatch\n",
    "from dart_math.utils import PROJ_HOME, init_logging, load_jsonl, save_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "    description=\"Grade: extract answers & judge correctness\", allow_abbrev=False\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--gen_fpath\",\n",
    "    type=str,\n",
    "    nargs=\"+\",\n",
    "    default=[os.path.join(PROJ_HOME, \"data/res/gen.jsonl\")],\n",
    "    help=\"Path to save results of generation (and evaluation).\",\n",
    ")\n",
    "\n",
    "args, unk_args = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "dev"
    ]
   },
   "outputs": [],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = EvaluatorMathBatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gen_fpath in args.gen_fpath:\n",
    "    logging.info(f\"Grade results in {gen_fpath=}\")\n",
    "    samples = [RespSampleVLLM(**sample) for sample in load_jsonl(gen_fpath)]\n",
    "    evaluator.batch_eval(samples)\n",
    "    save_jsonl([sample.to_dict() for sample in samples], gen_fpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
