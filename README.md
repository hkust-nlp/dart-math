# üéØDART-Math


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

> Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving

üìù
[Paper](https://tongyx361.github.io/assets/dart-math/paper-dart-math.pdf)¬†\|¬†ü§ó
[Datasets &
Models](https://huggingface.co/collections/hkust-nlp/dart-math-665704599b35de59f8fdf6c1)
\| üê± [Code](https://github.com/hkust-nlp/dart-math) \| üê¶ [X
(Twitter)](TODO)

<div align="center">

<img src="https://tongyx361.github.io/assets/dart-math/main-results.png" alt="Main results averaged on 2 in-domain and 4 challenging out-of-domain mathematical reasoning benchmarks." height=300px>
<img src="https://tongyx361.github.io/assets/dart-math/main-nresp-vs-query.png" alt="Number of responses v.s. query descending in difficulty in DART-Math datasets and similar-sized VRT baseline" height=300px>

</div>

<div align="left">

<sup> Figure 1: <strong>Left:</strong> Average accuracy on 6
mathematical benchmarks. We compare with models fine-tuned on the best,
public instruction tuning datasets for mathematical problem-solving:
MetaMath <a href="https://openreview.net/forum?id=N8N0hgNDRt">(Yu et
al., 2024)</a> with 395K examples, MMIQC
<a href="https://arxiv.org/abs/2401.09003">(Liu et al., 2024a)</a> with
2.3 million examples, as well as vanilla rejection tuning (VRT) with
590K examples. Both <em>DART-Math (Uniform)</em> and <em>DART-Math
(Prop2Diff)</em> use 590K training examples. <strong>Right:</strong>
Number of responses for each query descending by difficulty across 3
synthesis strategies. Queries are from the MATH training split
<a href="https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/be83ab3ecd0db773eb2dc1b0a17836a1-Abstract-round2.html">(Hendrycks
et al., 2021)</a>. VRT is the baseline biased towards easy queries,
while <em>Uniform</em> and <em>Prop2Diff</em> are proposed in this work
to balance and bias towards difficult queries respectively. Points are
slightly shifted and downsampled for clarity. </sup>

</div>

| Dataset                | Method         | \# of Samples |                                     Download                                     |
|:-----------------------|:---------------|--------------:|:--------------------------------------------------------------------------------:|
| `DART-Math-Uniform`    | DARS-Unifrom   |          591k |  ü§ó [HuggingFace](https://huggingface.co/datasets/hkust-nlp/dart-math-uniform)   |
| `DART-Math-Hard`       | DARS-Prop2Diff |          585k |    ü§ó [HuggingFace](https://huggingface.co/datasets/hkust-nlp/dart-math-hard)    |
| `DART-Math-Pool-MATH`  | DARS-Unifrom   |         1615k | ü§ó [HuggingFace](https://huggingface.co/datasets/hkust-nlp/dart-math-pool-math)  |
| `DART-Math-Pool-GSM8K` | DARS-Unifrom   |         2739k | ü§ó [HuggingFace](https://huggingface.co/datasets/hkust-nlp/dart-math-pool-gsm8k) |

| Model                               | [MATH](https://huggingface.co/datasets/hendrycks/competition_math) | [GSM8K](https://huggingface.co/datasets/gsm8k) | [CollegeMath](https://github.com/hkust-nlp/dart-math/tree/main/data/dsets/mwpbench/college-math-test.jsonl) |                                     Download                                      |
|:------------------------------------|-------------------------------------------------------------------:|-----------------------------------------------:|------------------------------------------------------------------------------------------------------------:|:---------------------------------------------------------------------------------:|
| `DART-Math-Llama-3-70B` (Uniform)   |                                                               54.9 |                                       **90.4** |                                                                                                    **38.5** |  ü§ó [HuggingFace](https://huggingface.co/hkust-nlp/dart-math-llama3-70b-uniform)  |
| `DART-Math-Llama-3-70B` (Prop2Diff) |                                                           **56.1** |                                           89.6 |                                                                                                        37.9 | ü§ó [HuggingFace](https://huggingface.co/hkust-nlp/dart-math-llama3-70b-prop2diff) |
| `DART-Math-DSMath-7B` (Uniform)     |                                                               52.9 |                                       **88.2** |                                                                                                        40.1 |  ü§ó [HuggingFace](https://huggingface.co/hkust-nlp/dart-math-dsmath-7b-uniform)   |
| `DART-Math-DSMath-7B` (Prop2Diff)   |                                                           **53.6** |                                           86.8 |                                                                                                    **40.7** | ü§ó [HuggingFace](https://huggingface.co/hkust-nlp/dart-math-dsmath-7b-prop2diff)  |
| `DART-Math-Mistral-7B` (Uniform)    |                                                               43.5 |                                       **82.6** |                                                                                                        26.9 |  ü§ó [HuggingFace](https://huggingface.co/hkust-nlp/dart-math-mistral-7b-uniform)  |
| `DART-Math-Mistral-7B` (Prop2Diff)  |                                                           **45.5** |                                           81.1 |                                                                                                    **29.4** | ü§ó [HuggingFace](https://huggingface.co/hkust-nlp/dart-math-mistral-7b-prop2diff) |
| `DART-Math-Llama-3-8B` (Uniform)    |                                                               45.3 |                                       **82.5** |                                                                                                        27.1 |  ü§ó [HuggingFace](https://huggingface.co/hkust-nlp/dart-math-llama3-8b-uniform)   |
| `DART-Math-Llama-3-8B` (Prop2Diff)  |                                                           **46.6** |                                           81.1 |                                                                                                    **28.8** | ü§ó [HuggingFace](https://huggingface.co/hkust-nlp/dart-math-llama3-8b-prop2diff)  |

## `DART-Math` Models: SOTA on Various In-Domain and Out-of-Domain Benchmarks

`DART-Math` models achieve performance **superior or competitive to
previous SOTAs** on 2 in-domain and 4 challenging out-of-domain
mathematical reasoning benchmarks, despite using **much smaller
datasets** and **no proprietary model like GPT-4**.

| Model                                                                                      | [MATH](https://huggingface.co/datasets/hendrycks/competition_math) | [GSM8K](https://huggingface.co/datasets/gsm8k) | [College](https://github.com/hkust-nlp/dart-math/tree/main/data/eval-dsets/mwpbench/college-math-test.jsonl) | [DM](https://github.com/hkust-nlp/dart-math/tree/main/data/eval-dsets/deepmind-mathematics.json) | [Olympiad](https://github.com/hkust-nlp/dart-math/tree/main/data/eval-dsets/olympiadbench/OE_TO_maths_en_COMP.json) | [Theorem](https://github.com/hkust-nlp/dart-math/tree/main/data/eval-dsets/theoremqa.json) |      AVG |
|:-------------------------------------------------------------------------------------------|-------------------------------------------------------------------:|-----------------------------------------------:|-------------------------------------------------------------------------------------------------------------:|-------------------------------------------------------------------------------------------------:|--------------------------------------------------------------------------------------------------------------------:|-------------------------------------------------------------------------------------------:|---------:|
| GPT-4 (0314)                                                                               |                           [52.6](https://arxiv.org/abs/2403.04706) |       [94.7](https://arxiv.org/abs/2403.04706) |                                                                     [24.4](https://arxiv.org/abs/2403.02884) |                                                                                                ‚Äì |                                                                                                                   ‚Äì |                                                                                          ‚Äì |        ‚Äì |
| Llama-3-70B-MetaMath                                                                       |                                                               44.9 |                                           88.0 |                                                                                                         31.9 |                                                                                             53.2 |                                                                                                                11.6 |                                                                                       21.9 |     41.9 |
| [`DART-Math-Llama-3-70B`](https://huggingface.co/hkust-nlp/dart-math-llama3-70b-prop2diff) |                                                           **56.1** |                                       **89.6** |                                                                                                     **37.9** |                                                                                         **64.1** |                                                                                                            **20.0** |                                                                                   **28.2** | **49.3** |
| DeepSeekMath-7B-MetaMath                                                                   |                                                               43.7 |                                           81.8 |                                                                                                         33.7 |                                                                                             53.0 |                                                                                                                13.6 |                                                                                       23.2 |     41.5 |
| [DeepSeekMath-7B-RL](https://huggingface.co/deepseek-ai/deepseek-math-7b-rl)               |                                                               53.1 |                                           88.4 |                                                                                                         41.3 |                                                                                             58.3 |                                                                                                                18.7 |                                                                                       35.9 |     49.3 |
| [`DART-Math-DSMath-7B`](https://huggingface.co/hkust-nlp/dart-math-dsmath-7b-prop2diff)    |                                                           **53.6** |                                       **86.8** |                                                                                                     **40.7** |                                                                                         **61.6** |                                                                                                            **21.7** |                                                                                   **32.2** | **49.4** |
| Mistral-7B-MetaMath                                                                        |                                                               29.8 |                                           76.5 |                                                                                                         19.3 |                                                                                             28.0 |                                                                                                                 5.9 |                                                                                       14.0 |     28.9 |
| [`DART-Math-Mistral-7B`](https://huggingface.co/hkust-nlp/dart-math-mistral-7b-prop2diff)  |                                                           **45.5** |                                       **81.1** |                                                                                                     **29.4** |                                                                                         **45.1** |                                                                                                            **14.7** |                                                                                   **17.0** | **38.8** |
| Llama-3-8B-MetaMath                                                                        |                                                               32.5 |                                           77.3 |                                                                                                         20.6 |                                                                                             35.0 |                                                                                                                 5.5 |                                                                                       13.8 |     30.8 |
| [`DART-Math-Llama-3-8B`](https://huggingface.co/hkust-nlp/dart-math-llama3-8b-prop2diff)   |                                                           **46.6** |                                       **81.1** |                                                                                                     **28.8** |                                                                                         **48.0** |                                                                                                            **14.5** |                                                                                   **19.4** | **39.7** |

<sup>**Abbreviations**: College (CollegeMath), DM (DeepMind
Mathematics), Olympiad (OlympiadBench-Math), Theorem (TheoremQA).
**Bold** means the best score by SFT on the respective base model here.
`DART-Math` models here are fine-tuned on the [`DART-Math-Hard`
dataset](https://huggingface.co/datasets/hkust-nlp/dart-math-hard).</sup>

## `DART-Math` Datasets: SOTA & Data-Efficient & Open-Source

`DART-Math` are the **state-of-the-art** and **data-efficient**
**open-source** instruction tuning datasets for mathematical reasoning.

Most of previous datasets are **constructed with ChatGPT**, and many of
them are **not open-source**, especially for ones of the best
performance.

| Math SFT Dataset                                                                   | \# of Samples (k) | Synthesis Agent(s)  |                                 Open-Source                                 |
|:-----------------------------------------------------------------------------------|------------------:|:--------------------|:---------------------------------------------------------------------------:|
| [WizardMath](https://arxiv.org/abs/2308.09583)                                     |                96 | GPT-4               |                                      ‚úó                                      |
| [MetaMathQA](https://arxiv.org/abs/2309.12284)                                     |               395 | GPT-3.5             |          [‚úì](https://huggingface.co/datasets/meta-math/MetaMathQA)          |
| [MMIQC](https://arxiv.org/abs/2401.09003)                                          |              2294 | GPT-4+GPT-3.5+Human |             [‚úì](https://huggingface.co/datasets/Vivacem/MMIQC)              |
| [Orca-Math](https://arxiv.org/abs/2402.14830)                                      |               200 | GPT-4               | [‚úì](https://huggingface.co/datasets/microsoft/orca-math-word-problems-200k) |
| [Xwin-Math-V1.1](https://arxiv.org/abs/2403.04706)                                 |              1440 | GPT-4               |                                      ‚úó                                      |
| [KPMath-Plus](https://arxiv.org/abs/2403.02333)                                    |              1576 | GPT-4               |                                      ‚úó                                      |
| [MathScaleQA](https://arxiv.org/abs/2403.02884)                                    |              2021 | GPT-3.5+Human       |                                      ‚úó                                      |
| [`DART-Math-Uniform`](https://huggingface.co/datasets/hkust-nlp/dart-math-uniform) |               591 | DeepSeekMath-7B-RL  |      [‚úì](https://huggingface.co/datasets/hkust-nlp/dart-math-uniform)       |
| [`DART-Math-Hard`](https://huggingface.co/datasets/hkust-nlp/dart-math-hard)       |               585 | DeepSeekMath-7B-RL  |        [‚úì](https://huggingface.co/datasets/hkust-nlp/dart-math-hard)        |

## `DARS` ‚Äì Difficulty-Aware Rejection Sampling

Our analysis of previous datasets reveals **severe biases towards easy
queries**, with **frequent failures to generate any correct response for
the most challenging queries**.

This primarily arises from their constuction method, **vanilla rejection
sampling**, where **the same number** of responses are sampled for each
query, yet the likelihood of obtaining correct responses for difficult
queries is significantly lower, sometimes even zero.

Motivated by the observation above and the intuitive that difficult
samples are critical for learning complexing reasoning, we propose
**Difficulty-Aware Rejection Sampling** (`DARS`) to eliminate the bias
towards easy queries. Specifically, we introduce two strategies to
increase the number of correct responses for difficult queries:

1.  **Uniform**, which involves sampling responses for each query until
    **each query accumulates $k_u$ correct responses**, where $k_u$ is a
    preset hyperparameter determined by the desired size of the
    synthetic dataset;
2.  **Prop2Diff**, where we continue sampling responses until the number
    of correct responses for each query is **proportional to its
    difficulty score**. The most challenging queries will receive $k_p$
    responses and kp is a hyperparameter. This method introduces a
    deliberate bias in the opposite direction to vanilla rejection
    sampling, towards more difficult queries, inspired by previous works
    that demonstrate **difficult samples can be more effective to
    enhance model capabilities** ([Sorscher et al.,
    2022](https://proceedings.neurips.cc/paper_files/paper/2022/hash/7b75da9b61eda40fa35453ee5d077df6-Abstract-Conference.html);
    [Liu et al., 2024b](https://openreview.net/forum?id=BTKAeLqLMw)).

See [Figure 1
(Right)](https://tongyx361.github.io/assets/dart-math/main-nresp-vs-query.png)
for examples of `DART-Math-Uniform` by `DARS-Uniform` and
`DART-Math-Hard` by `DARS-Prop2Diff`.

## üöÄ Quick Start / Reproduction

### ‚öôÔ∏è Setup

We recommend using¬†[Conda](https://docs.conda.io/projects/miniconda) and
[pip](https://pip.pypa.io/en/stable/#)¬†to manage your environment. Run
the following commands to setup your environment:

``` shell
git clone https://github.com/hkust-nlp/dart-math.git && cd dart-math
conda create --name dart-math --yes python=3.11
conda activate dart-math
pip install -r requirements.txt
pip install flash-attn --no-build-isolation
```

For common users/developers, please just run the following command the
install the `dart-math` package:

``` shell
pip install -e "."
```

For intended contributors, we recommend installing the package with the
`dev` extras:

``` shell
pip install -e ".[dev]"
pre-commit install
```

### üî® Training

We implement an efficient training pipeline utilizing various
techniques. Notably, [**sequence
packing**](https://hkust-nlp.github.io/dart-math/train.html#sequence-packing)
accelerates training by 6-8x in our setting and possibly more in other
settings. (See [how to integrate sequence packing in 4 lines of
code](https://hkust-nlp.github.io/dart-math/train.html#accelerating-several-times-with-sequence-packing-in-4-lines-of-code).)

Please refer to

- the [training Python
  script](https://github.com/hkust-nlp/dart-math/blob/main/pipeline/train.py)
  for code of training based on the [HuggingFace
  `Trainer`](https://huggingface.co/docs/transformers/en/main_classes/trainer)
  and utilizing [sequence
  packing](https://hkust-nlp.github.io/dart-math/train.html#sequence-packing).
- the
  [single-node](https://github.com/hkust-nlp/dart-math/blob/main/scripts/train-single-node.sh)/[multi-node](https://github.com/hkust-nlp/dart-math/blob/main/scripts/train-multi-node.sh)
  training `bash` script for code of training based on [HuggingFace
  `accelerate`](https://huggingface.co/docs/accelerate/index) and
  [`deepspeed`](https://www.deepspeed.ai)

Here, we provide some example commands as well as reproduction
instructions for our work:

#### Single-Node Training

For example, to reproduce training `DART-Math-Llama3-8B-Prop2Diff` on a
node of 8 A100 GPUs, please run the following command:

``` shell
bash scripts/train-single-node.sh \
    --data_path "hkust-nlp/dart-math-hard" \
    --model_path "meta-llama/Meta-Llama-3-8B" \
    --lr "5e-5" --bs 64 --n_grad_acc_steps 1 --n_epochs 1 \
    --gpu_ids "0,1,2,3,4,5,6,7" \
    --output_dir "models/dart-math-llama3-8b-prop2diff"
```

To reproduce other training settings, just refer to the paper and modify
the `--data_path`, `--model_path`, `--lr`, `--n_grad_acc_steps`,
`--n_epochs` and `--output_dir` arguments accordingly.

#### Multi-Node Training

To reproduce training `DART-Math-Llama3-70B-Prop2Diff` on 4 nodes of 8
A100 GPUs, please first edit the `cfgs/deepspeed/hostfile` according to
your enviroment and then run the following command:

``` shell
bash scripts/train-multi-node.sh \
    --data_path "hkust-nlp/dart-math-hard" \
    --model_path "meta-llama/Meta-Llama-3-70B" \
    --lr "2e-5" --bs 64 --n_grad_acc_steps 1 --n_epochs 1 \
    --n_nodes 4 \
    --output_dir "models/dart-math-llama3-70b-prop2diff"
```

To reproduce training `DART-Math-Llama3-70B-Uniform` on 4 nodes of 8
A100 GPUs, just change `--data_path` to `"hkust-nlp/dart-math-uniform"`.

<details>
<summary>
The off-the-shelf command to train `DART-Math-Llama3-70B-Uniform`
</summary>

``` shell
bash scripts/train-multi-node.sh \
    --data_path "hkust-nlp/dart-math-uniform" \
    --model_path "meta-llama/Meta-Llama-3-70B" \
    --lr "2e-5" --bs 64 --n_grad_acc_steps 1 --n_epochs 1 \
    --n_nodes 4 \
    --output_dir "models/dart-math-llama3-70b-prop2diff"
```

</details>

### ‚öñÔ∏è Evaluation

We utilize [vLLM](https://docs.vllm.ai/en/latest/index.html) to
accelerate inference and an elaborate answer extraction and correctness
judgement pipeline based on regular expressions and
[SymPy](https://www.sympy.org) symbolic calculation, which is able to
correctly process

- most **mathematical objects** such as matrices (vectors), intervals,
  symbols besides numbers,
- as well as some **special texts** like bool expressions, dates and
  times.

For example, to reproduce one pass of greedy decoding with
`DART-Math-Mistral-7B-Prop2Diff` on the 6 benchmarks in Table 2 on GPU
0, please run the following command:

``` shell
CUDA_VISIBLE_DEVICES="0" python pipeline/gen.py \
    --gen_save_path "data/res/dart-math-mistral-7b-prop2diff.jsonl" \
    --model_name_or_path "hkust-nlp/dart-math-mistral-7b-prop2diff" \
    --datasets "math-test" "gsm8k-test" "mwpbench/college-math-test" "deepmind-mathematics" \
        "olympiadbench/OE_TO_maths_en_COMP" "theoremqa" \
    --max_new_tokens 2048 --temperature 0 --top_p 0.95 \
    --prompt_template "alpaca" --n_shots -1 \
    --inf_seed -1 \
    --max_n_trials 1
```

To reproduce other inference settings, just refer to the paper and
modify the `--model_name_or_path` and `--gen_save_path` arguments
accordingly.

For other general inference settings, please modify the command or
directly modify the
[script](https://github.com/hkust-nlp/dart-math/blob/main/pipeline/gen.py).

You can also add the `--gen_only` option to only generate responses
without evaluation and use the
[`EvaluatorMathBatch`](https://hkust-nlp.github.io/dart-math/eval.html#evaluatormathbatch)
to evaluate the generations by yourself.

### üóÇ Data Synthesis

Our data synthesis pipeline is compatible with the evaluation pipeline.

For example, to reproduce synthesis of `DART-Math-Uniform`, run the
following command with different GPUs, please run the following command:

``` shell
CUDA_VISIBLE_DEVICES="0" python pipeline/gen.py \
    --gen_save_path "data/res/dart-math-uniform.jsonl" \
    --model_name_or_path "deepseek-ai/deepseek-math-7b-rl" \
    --datasets "math-train" "gsm8k-train" \
    --max_new_tokens 2048 --temperature 1.6 --top_p 0.95 \
    --prompt_template "deepseekmath" --n_shots 0 \
    --inf_seed -1 \
    --min_n_corrects 40 --max_n_trials 0 # unlimited, should be killed manually
```

## [`dart-math` Package](https://hkust-nlp.github.io/dart-math): Efficient and Flexible Training & Inference & Evaluation Pipelines

We package our code of effcient and flexible training & inference &
evaluation pipelines into `dart-math` and document it at [this
website](https://hkust-nlp.github.io/dart-math/quick-start.html).

The `dart-math` package provides the following useful features besides
ones mentioned above:

- **Tool-integrated reasoning**: reasoning in natural language
  interleaved with Python code (see the `code_exec_cfg` attribute of
  [`Generator`](https://hkust-nlp.github.io/dart-math/gen.html#generator));
- ‚Ä¶

## Acknowlegements

Thanks to:

- [`nbdev`](https://nbdev.fast.ai/) for generating the [wonderful
  documentation website](https://hkust-nlp.github.io/dart-math),
- [`stanford_alpaca`](https://github.com/tatsu-lab/stanford_alpaca) for
  reference code about training,
- [`functionary`](https://github.com/MeetKai/functionary/tree/main/functionary/train/packing)
  for reference code about [sequence
  packing](https://hkust-nlp.github.io/dart-math/train.html#sequence-packing).

## Citation

If you find our data, model or code useful for your work, please kindly
cite [our
paper](https://tongyx361.github.io/assets/dart-math/paper-dart-math.pdf):

``` latex
@article{tong2024dartmath,
  author = {Yuxuan Tong, Xiwen Zhang, Rui Wang, Ruidong Wu, Junxian He},
  title = {DART-Math: Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving},
  year = {2024},
  publisher = {GitHub},
  journal = {preprint},
  howpublished = {https://tongyx361.github.io/assets/dart-math/paper-dart-math.pdf},
}
```
