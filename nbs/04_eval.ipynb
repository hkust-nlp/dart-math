{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Math) Evalution\n",
    "\n",
    "> Elaborate answer extraction and correctness judgement (for mathematical evaluation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dart_math.eval import *\n",
    "\n",
    "math_evaluator = EvaluatorMathBatch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elaborate Mathematical Evaluation Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/hkust-nlp/dart-math/blob/main/dart_math/eval.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### EvaluatorMath\n",
       "\n",
       ">      EvaluatorMath (use_orig_eq_for_olympiadbench:bool=True,\n",
       ">                     include_percentage:bool=True, rel_tol:float=0.001,\n",
       ">                     ascii_only:bool=True)\n",
       "\n",
       "*Evaluator for math problems, capable of extracting answer segment from complex resp and processing various mathematical objects\n",
       "(e.g. fractions, symbolic expressions, matrices, vectors) and special text (e.g. bool values).*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| use_orig_eq_for_olympiadbench | bool | True | Whether to use the original implementation of `eq` for OlympiadBench.<br>For OlympiadBench, by default, we use the official implementation of `eq` by He et al. (2024),<br>which utilizing the numerical error range information provided with query,<br>but keep the `extract_nas` of ours,<br>because the official implementation fails to extract a non-negligible part of answers, especially for base model ICL.<br>You could set `use_orig_eq_for_olympiadbench` to `False` to use our implementation of `eq`<br>for better consistency across benchmarks in our evaluation setting. |\n",
       "| include_percentage | bool | True | Whether to include percentage comparisons. |\n",
       "| rel_tol | float | 0.001 | The relative tolerance for numerical comparisons. |\n",
       "| ascii_only | bool | True | Only allowing ASCII characters |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/hkust-nlp/dart-math/blob/main/dart_math/eval.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### EvaluatorMath\n",
       "\n",
       ">      EvaluatorMath (use_orig_eq_for_olympiadbench:bool=True,\n",
       ">                     include_percentage:bool=True, rel_tol:float=0.001,\n",
       ">                     ascii_only:bool=True)\n",
       "\n",
       "*Evaluator for math problems, capable of extracting answer segment from complex resp and processing various mathematical objects\n",
       "(e.g. fractions, symbolic expressions, matrices, vectors) and special text (e.g. bool values).*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| use_orig_eq_for_olympiadbench | bool | True | Whether to use the original implementation of `eq` for OlympiadBench.<br>For OlympiadBench, by default, we use the official implementation of `eq` by He et al. (2024),<br>which utilizing the numerical error range information provided with query,<br>but keep the `extract_nas` of ours,<br>because the official implementation fails to extract a non-negligible part of answers, especially for base model ICL.<br>You could set `use_orig_eq_for_olympiadbench` to `False` to use our implementation of `eq`<br>for better consistency across benchmarks in our evaluation setting. |\n",
       "| include_percentage | bool | True | Whether to include percentage comparisons. |\n",
       "| rel_tol | float | 0.001 | The relative tolerance for numerical comparisons. |\n",
       "| ascii_only | bool | True | Only allowing ASCII characters |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(EvaluatorMath, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`EvaluatorMath` implements an elaborate evaluation pipeline for mathematical reasoning tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accurately Extracting Answer Strings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`EvaluatorMath` can:\n",
    "\n",
    "1. **extract** short answers from long responses rather **accurately**\n",
    "2. and **normalize** into a **mathematical** expression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATH-style boxed answer\n",
    "math_evaluator.extract_ans(\"Therefore, $1+1=\\\\boxed{2}$.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer around \"answer\"\n",
    "math_evaluator.extract_ans(\n",
    "    \"Both $1$ and $11$ divide $11,$ so $\\\\boxed{11}=2$, and since $1,$ $2,$ $4,$ $5,$ $10,$ and $20$ divide $20,$ then $\\\\boxed{20}=6$. The inner expression, $\\\\boxed{11}\\\\times\\\\boxed{20}=2\\\\times6=12$. Finally, $\\\\boxed{12}=6$ because $1,$ $2,$ $3,$ $4,$ $6,$ and $12$ divide $12.$\\n\\nTherefore, $6$ is our answer. Please note that we have not boxed the correct answer as we normally do, as that would be especially confusing for this problem.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'360'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the last number by default\n",
    "math_evaluator.extract_ans(\n",
    "    'First, we need to count the total number of letters in the word \"CIRCLE\". There are 6 letters.\\n\\nNext, we need to count the number of distinct letters. There are 6 distinct letters in the word \"CIRCLE\": C, I, R, L, E, and G.\\n\\nNow, let\\'s consider the arrangements of the distinct letters. The number of ways to arrange n distinct items is n factorial (n!). So, we have 6! = 6 × 5 × 4 × 3 × 2 × 1 = 720 ways to arrange the distinct letters.\\n\\nHowever, the word \"CIRCLE\" has one letter that repeats (the letter \\'C\\' repeats twice). We have over-counted the number of distinct arrangements by including arrangements that are just rotations of each other (for example, \"CIRCLE\" and \"LCIRCE\" are considered different arrangements here, but they are the same word when read).\\n\\nTo correct for this, we divide the total number of arrangements by the number of ways to arrange the repeated letters. The number of ways to arrange 2 identical items is 2! = 2 × 1 = 2. So, we divide the total number of arrangements by 2 to get the correct number of distinct arrangements.\\n\\nTherefore, the number of ways to arrange the letters of the word \"CIRCLE\" is 720 ÷ 2 = 360.'\n",
    ")\n",
    "# More cases ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\frac{1}{2}'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize fraction\n",
    "math_evaluator.extract_ans(\"The answer is 1/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{array}3\\\\\\\\frac{\\\\pi}{2}\\\\end{array}'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize pmatrix\n",
    "math_evaluator.extract_ans(\n",
    "    \"The answer is \\\\begin{pmatrix} 3 \\\\\\\\ \\\\frac{\\\\pi}{2} \\\\end{pmatrix}\"\n",
    ")\n",
    "# More cases ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correctly Processing Various Mathematical Objects / Special Text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`EvaluatorMath`, based on regular expressions and [SymPy](https://www.sympy.org) symbolic calculation, is able to correctly process\n",
    "\n",
    "- most **mathematical objects** such as matrices (vectors), intervals, symbols besides numbers,\n",
    "- as well as some **special texts** like bool expressions, dates and times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_evaluator.eq(\"x+y\", \"y+x\") == True  # Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_evaluator.eq(\"\\\\frac{1}{2}\", \"0.5\") == True  # LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_evaluator.eq(\n",
    "    \"\\\\begin{array}1\\\\\\\\2\\\\end{array}\",\n",
    "    \"1,2\",\n",
    ")  # Matrix (Vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_evaluator.eq(\"{1,2}\", \"{2,1}\", compare_sets=True)  # Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_evaluator.eq(\"no\", \"false\")  # Bool\n",
    "# More mathematical objects and special texts ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More test cases:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |code-fold: true\n",
    "test_eq(math_evaluator.eq(\"251,7\\\\\\\\ \\\\noindent\", \"0\"), False)\n",
    "test_eq(math_evaluator.eq(\"3.54*10^{-7}\", \"3.54e-07\"), True)\n",
    "test_eq(math_evaluator.eq(r\"\\frac{1}{2}\", \"0.5\"), True)\n",
    "test_eq(math_evaluator.eq(\"1\", \"100\"), False)\n",
    "test_eq(math_evaluator.eq(\"100\", \"1\"), False)\n",
    "test_eq(math_evaluator.eq(\"3.04\", \"0.0304\", False), True)\n",
    "test_eq(math_evaluator.eq([\"0.0304\", 0.0304], \"3.04\"), True)\n",
    "test_eq(math_evaluator.eq(\"x<-1\", \"x>3\"), False)\n",
    "test_eq(\n",
    "    math_evaluator.eq(\"(-\\\\infty,0)\\\\cup(0,\\\\infty)\", \"(-\\\\infty,0)\\\\cup(0,\\\\infty)\"),\n",
    "    True,\n",
    ")\n",
    "test_eq(math_evaluator.eq(\"1+2,2+1\", \"2+1,1+2\"), True)\n",
    "test_eq(math_evaluator.eq(5, 5), True)\n",
    "test_eq(math_evaluator.eq(0.1 + 0.2, 0.3), True)\n",
    "test_eq(math_evaluator.eq(\"x + y\", \"y + x\"), True)\n",
    "test_eq(math_evaluator.eq(\"C\", \"C\"), True)\n",
    "test_eq(math_evaluator.eq(\"1,234\", \"1234\"), True)\n",
    "test_eq(math_evaluator.eq(\"12,34\", \"(12,34)\"), True)\n",
    "\n",
    "test_eq(math_evaluator.eq(\"\\\\$ 5\", \"5\"), True)\n",
    "test_eq(math_evaluator.eq(\"3 * \\\\sqrt{13}\", \"3\\\\sqrt{13}\"), True)\n",
    "test_eq(math_evaluator.eq(\"\\\\pi/2\", \"\\\\frac{\\\\pi}{2}\"), True)\n",
    "test_eq(math_evaluator.eq(\"(3,\\\\pi/2)\", \"(3,\\\\frac{\\\\pi}{2})\"), True)\n",
    "test_eq(math_evaluator.eq(\"23000\", \"\\\\$23{,}000\"), True)\n",
    "test_eq(\n",
    "    math_evaluator.eq(r\"\\left(1,2\\right)\", r\"\\left(2,1\\right)\", compare_sets=True), True\n",
    ")\n",
    "test_eq(math_evaluator.eq(\"White\", \"white\"), True)\n",
    "test_eq(math_evaluator.eq(\"[0,3)\", \"[0,1]\"), False)\n",
    "test_eq(math_evaluator.eq(\"[0,1]\", \"[0,3)\"), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/hkust-nlp/dart-math/blob/main/dart_math/eval.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### EvaluatorMathBatch\n",
       "\n",
       ">      EvaluatorMathBatch (use_orig_eq_for_olympiadbench:bool=True,\n",
       ">                          include_percentage:bool=True, rel_tol:float=0.001,\n",
       ">                          ascii_only:bool=True, timeout:int=5)\n",
       "\n",
       "*Batch evaluator for math problems, capable of extracting answer segment from complex resp and processing various mathematical objects\n",
       "(e.g. fractions, symbolic expressions, matrices, vectors) and special text (e.g. bool values).*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| use_orig_eq_for_olympiadbench | bool | True | Whether to use the original implementation of `eq` for OlympiadBench.<br>For OlympiadBench, by default, we use the official implementation of `eq` by He et al. (2024),<br>which utilizing the numerical error range information provided with query,<br>but keep the `extract_nas` of ours,<br>because the official implementation fails to extract a non-negligible part of answers, especially for base model ICL.<br>You could set `use_orig_eq_for_olympiadbench` to `False` to use our implementation of `eq`<br>for better consistency across benchmarks in our evaluation setting. |\n",
       "| include_percentage | bool | True | Whether to include percentage comparisons. |\n",
       "| rel_tol | float | 0.001 | The relative tolerance for numerical comparisons. |\n",
       "| ascii_only | bool | True | Only allowing ASCII characters |\n",
       "| timeout | int | 5 |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/hkust-nlp/dart-math/blob/main/dart_math/eval.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### EvaluatorMathBatch\n",
       "\n",
       ">      EvaluatorMathBatch (use_orig_eq_for_olympiadbench:bool=True,\n",
       ">                          include_percentage:bool=True, rel_tol:float=0.001,\n",
       ">                          ascii_only:bool=True, timeout:int=5)\n",
       "\n",
       "*Batch evaluator for math problems, capable of extracting answer segment from complex resp and processing various mathematical objects\n",
       "(e.g. fractions, symbolic expressions, matrices, vectors) and special text (e.g. bool values).*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| use_orig_eq_for_olympiadbench | bool | True | Whether to use the original implementation of `eq` for OlympiadBench.<br>For OlympiadBench, by default, we use the official implementation of `eq` by He et al. (2024),<br>which utilizing the numerical error range information provided with query,<br>but keep the `extract_nas` of ours,<br>because the official implementation fails to extract a non-negligible part of answers, especially for base model ICL.<br>You could set `use_orig_eq_for_olympiadbench` to `False` to use our implementation of `eq`<br>for better consistency across benchmarks in our evaluation setting. |\n",
       "| include_percentage | bool | True | Whether to include percentage comparisons. |\n",
       "| rel_tol | float | 0.001 | The relative tolerance for numerical comparisons. |\n",
       "| ascii_only | bool | True | Only allowing ASCII characters |\n",
       "| timeout | int | 5 |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(EvaluatorMathBatch, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SymPy symbolic calculation causes risks of ex-long evaluation time.\n",
    "\n",
    "To address this, we implement `EvaluatorMathBatch` to evaluate in batch with **timeout** but still efficiently (based on `asyncio` coroutines instead of `multiprocessing` in previous implementations).\n",
    "\n",
    "```python\n",
    "answers, corrects = math_evalutor.batch_eval(resp_samples)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/hkust-nlp/dart-math/blob/main/dart_math/eval.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### EvaluatorBase\n",
       "\n",
       ">      EvaluatorBase ()\n",
       "\n",
       "*Base class for evaluators.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/hkust-nlp/dart-math/blob/main/dart_math/eval.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### EvaluatorBase\n",
       "\n",
       ">      EvaluatorBase ()\n",
       "\n",
       "*Base class for evaluators.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(EvaluatorBase, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/hkust-nlp/dart-math/blob/main/dart_math/eval.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### EvaluatorBatchBase\n",
       "\n",
       ">      EvaluatorBatchBase (timeout:int=5)\n",
       "\n",
       "*Base class for batch evaluators, providing additional method for batch evaluation.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| timeout | int | 5 | The timeout for each evaluation in seconds. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/hkust-nlp/dart-math/blob/main/dart_math/eval.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### EvaluatorBatchBase\n",
       "\n",
       ">      EvaluatorBatchBase (timeout:int=5)\n",
       "\n",
       "*Base class for batch evaluators, providing additional method for batch evaluation.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| timeout | int | 5 | The timeout for each evaluation in seconds. |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(EvaluatorBatchBase, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing LaTeX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dart_math.eval import latex2sympy_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-11, -10\\right)$"
      ],
      "text/plain": [
       "Interval.open(-11, -10)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latex2sympy_interval(\"(-11,-10)\\\\cup\\\\{-\\\\sqrt{110}\\\\}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-\\infty, 0\\right) \\cup \\left(0, \\infty\\right)$"
      ],
      "text/plain": [
       "Union(Interval.open(-oo, 0), Interval.open(0, oo))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latex2sympy_interval(\"(-\\\\infty, 0) \\\\cup (0, \\\\infty)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(a + b, b\\right]$"
      ],
      "text/plain": [
       "Interval.Lopen(a + b, b)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latex2sympy_interval(\"(a+b,b]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix / Vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}\\sqrt{400 \\cos^{2}{\\left(\\frac{9 \\pi}{44} \\right)}} & \\frac{\\pi}{4}\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([[sqrt(400*cos((9*pi)/44)**2), pi/4]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_evaluator.latex2matrix(r\"\\sqrt{400\\cos^2(9\\pi/44)},\\frac{\\pi}{4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}\\frac{1}{2} & 0 & - \\frac{\\sqrt{3}}{2}\\\\0 & 1 & 0\\\\\\frac{\\sqrt{3}}{2} & 0 & \\frac{1}{2}\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[      1/2, 0, -1*sqrt(3)/2],\n",
       "[        0, 1,            0],\n",
       "[sqrt(3)/2, 0,          1/2]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_evaluator.latex2matrix(\n",
    "    r\"\\begin{pmatrix} \\frac{1}{2} & 0 & -\\frac{\\sqrt{3}}{2} \\\\ 0 & 1 & 0 \\\\ \\frac{\\sqrt{3}}{2} & 0 & \\frac{1}{2} \\end{pmatrix}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(\n",
    "    math_evaluator.latex2matrix(\"\\\\begin{pmatrix}-18\\\\\\\\-49\\\\\\\\96\\\\end{pmatrix}\"),\n",
    "    Matrix([[-18, -49, 96]]),\n",
    ")\n",
    "test_eq(\n",
    "    math_evaluator.latex2matrix(\"\\\\begin{pmatrix} 2 & 3 \\\\\\\\ 0 & -2 \\\\end{pmatrix}\"),\n",
    "    Matrix([[2, 3], [0, -2]]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(math_evaluator.norm_math_str(\"251,7\\\\\\\\ \\\\noindent\"), \"251,7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(fix_a_slash_b(\"(3/4)\\\\sqrt{3}\"), \"(\\\\frac{3}{4})\\\\sqrt{3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(math_evaluator.norm_pm(\"x\\\\pmy\"), \"x-y,x+y\")\n",
    "test_eq(math_evaluator.norm_pm(\"a\\\\mpb\"), \"a-b,a+b\")\n",
    "test_eq(math_evaluator.norm_pm(\"1\\\\pm\\\\sqrt{19}\"), \"1-\\\\sqrt{19},1+\\\\sqrt{19}\")\n",
    "test_eq(math_evaluator.norm_pm(r\"\\{1\\pm\\sqrt{5},-2\\}\"), \"1-\\\\sqrt{5},1+\\\\sqrt{5},-2\")\n",
    "test_eq(\n",
    "    math_evaluator.norm_pm(\"\\\\(\\\\frac{1\\\\pm\\\\sqrt{17}}{4}\\\\)\"),\n",
    "    \"\\\\frac{1-\\\\sqrt{17}}{4},\\\\frac{1+\\\\sqrt{17}}{4}\",\n",
    ")\n",
    "test_eq(\n",
    "    math_evaluator.norm_pm(r\"\\frac{1\\pm\\sqrt{1-\\frac{2}{\\sqrt{3}}}}{1}\"),\n",
    "    \"\\\\frac{1-\\\\sqrt{1-\\\\frac{2}{\\\\sqrt{3}}}}{1},\\\\frac{1+\\\\sqrt{1-\\\\frac{2}{\\\\sqrt{3}}}}{1}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(norm_deg(r\"20^\\circ\"), r\"20\")\n",
    "test_eq(norm_deg(r\"\\sin 20^\\circ\"), r\"\\sin {20*\\frac{\\pi}{180}}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(math_evaluator.norm_basic_fn(r\"sinx\"), r\"\\sin^{1}x\")\n",
    "test_eq(math_evaluator.norm_basic_fn(r\"\\sin^2x\"), r\"\\sin^{2}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(math_evaluator.extract_set(\"{2,1}\"), [\"1\", \"2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(is_set(\"{2,1}\"), True)\n",
    "test_eq(is_set(\"orange\"), False)\n",
    "test_eq(is_set(\"x<-1orx>3\"), True)\n",
    "test_eq(is_set(\"(3/4)sqrt(3)\"), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(math_evaluator.remove_first_paren_pair(\"{white}\", \"{\"), \"white\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
